{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ganesh_Kumaran_Masilamani_(200434339)4_5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOvtwOLqktTa",
        "outputId": "9ca54274-c737-4e11-9310-2b871b942038",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#list of libraries imported\n",
        "import csv                              \n",
        "from sklearn.svm import LinearSVC\n",
        "from nltk.classify import SklearnClassifier\n",
        "from random import shuffle\n",
        "#machine learning library for support vector machine\n",
        "from sklearn.pipeline import Pipeline                           #used for training and validating the classifier\n",
        "from sklearn.metrics import accuracy_score                      #used to find accuracy\n",
        "from sklearn.metrics import precision_recall_fscore_support     #used to find precision, recall, fscore\n",
        "import nltk\n",
        "import numpy as np                                              \n",
        "import string\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import stopwords                               #used for preprocessing\n",
        "from nltk.stem import WordNetLemmatizer                         #used for preprocessing"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mKtZvbcktTp"
      },
      "source": [
        "# load data from a file and append it to the rawData\n",
        "def loadData(path, Text=None):  \n",
        "    with open(path) as f:\n",
        "        reader = csv.reader(f, delimiter='\\t')\n",
        "        next(reader)\n",
        "        for line in reader:\n",
        "          #used product_ID, product_title, review_title as extra features\n",
        "            (Id, product_ID, product_title, review_title, Text, Label) = parseReview(line)\n",
        "            rawData.append((Id, product_ID, product_title, review_title, Text, Label)) #rawData.append((Id, preProcess(Text), Label))\n",
        "            \n",
        "        \n",
        "def splitData(percentage):\n",
        "    # A method to split the data between trainData and testData \n",
        "    dataSamples = len(rawData)\n",
        "    #to find half of data\n",
        "    halfOfData = int(len(rawData)/2)\n",
        "    #to find training samples\n",
        "    trainingSamples = int((percentage*dataSamples)/2)\n",
        "    #splitting of trainData\n",
        "    for (_, product_ID, product_title, review_title, Text, Label) in rawData[:trainingSamples] + rawData[halfOfData:halfOfData+trainingSamples]:\n",
        "        trainData.append((toFeatureVector(product_ID, product_title, review_title, preProcess(Text)),Label))\n",
        "    #splitting of testData    \n",
        "    for (_, product_ID, product_title, review_title, Text, Label) in rawData[trainingSamples:halfOfData] + rawData[halfOfData+trainingSamples:]:\n",
        "        testData.append((toFeatureVector(product_ID, product_title, review_title, preProcess(Text)),Label))"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRs6KwxNktT2"
      },
      "source": [
        "# Question 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiQn2mXIktT4"
      },
      "source": [
        "# Convert line from i/p file into an id/text/label\n",
        "def parseReview(reviewLine):\n",
        "    a='' #test case contains a single string a\n",
        "    if reviewLine[1]=='__label1__':#assigning a label to reviewline\n",
        "        a = 'fake review' #characters of the string\n",
        "    else: \n",
        "        'real review'     #characters of the string\n",
        "    return (reviewLine[0], reviewLine[2], reviewLine[3],reviewLine[4], reviewLine[8], a)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faLM0ol4ktUD"
      },
      "source": [
        "#Text preprocessing and feature vectorization\n",
        "#improving preprocessing by using lemmatization , bigrams, stopwords  \n",
        "#string of review text with is the input\n",
        "table = str.maketrans({key: None for key in string.punctuation})\n",
        "def preProcess(text):\n",
        "    # Should return a list of tokens using lemmatizer\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    #returns an actual word of the language, it is used where it is necessary to get valid words\n",
        "    filtered_tokens=[]\n",
        "    lemmatized_tokens = []\n",
        "    #setting stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    #filter out useless data\n",
        "    text = text.translate(table)\n",
        "    for w in text.split(\" \"):\n",
        "        if w not in stop_words:\n",
        "            lemmatized_tokens.append(lemmatizer.lemmatize(w.lower()))\n",
        "            #generate such word pairs from the existing sentence maintain their current sequences\n",
        "            #filter tokens using bigrams\n",
        "        filtered_tokens = [' '.join(l) for l in nltk.bigrams(lemmatized_tokens)] + lemmatized_tokens\n",
        "    return filtered_tokens"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFwqGzmNktUK"
      },
      "source": [
        "# Question 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxc0KH20ktUM"
      },
      "source": [
        "featureDict = {} # A global dict of features\n",
        "#preprocessed review should return a dictionary that has as its keys the tokens, and as values the weight of those tokens in the preprocessed reviews\n",
        "#used to validate for loop, for every token\n",
        "#validate if it is present already in featuredict or dict\n",
        "#using product_ID, product_title, review_title as extra features from data set\n",
        "\n",
        "def toFeatureVector(product_ID, product_title, review_title, tokens):\n",
        "    Dict = {}\n",
        "    \n",
        "#for product_ID\n",
        "\n",
        "    for PI in product_ID:\n",
        "        try:\n",
        "          i= featureDict[PI]\n",
        "        except KeyError:\n",
        "          i = len(featureDict) + 1\n",
        "          featureDict[PI] = i\n",
        "        try:  \n",
        "           Dict[i] += (1.0/len(product_ID))\n",
        "        except KeyError:\n",
        "           Dict[i] = (1.0/len(product_ID))  \n",
        "   \n",
        "#for product_title\n",
        "\n",
        "    for PT in product_title:\n",
        "        try:\n",
        "          i= featureDict[PT]\n",
        "        except KeyError:\n",
        "          i = len(featureDict) + 1\n",
        "          featureDict[PT] = i\n",
        "        try:  \n",
        "           Dict[i] += (1.0/len(product_title))\n",
        "        except KeyError:\n",
        "           Dict[i] = (1.0/len(product_title))  \n",
        "    \n",
        "#for review_title\n",
        "\n",
        "    \n",
        "    for RT in review_title:\n",
        "        try:\n",
        "          i= featureDict[RT]\n",
        "        except KeyError:\n",
        "          i = len(featureDict) + 1\n",
        "          featureDict[RT] = i\n",
        "        try:  \n",
        "           Dict[i] += (1.0/len(review_title))\n",
        "        except KeyError:\n",
        "           Dict[i] = (1.0/len(review_title))  \n",
        "                 \n",
        "#for Text        \n",
        "\n",
        "    for token in tokens:\n",
        "        try:\n",
        "          i= featureDict[token]\n",
        "        except KeyError:\n",
        "          i = len(featureDict) + 1\n",
        "          featureDict[token] = i\n",
        "        try:  \n",
        "           Dict[i] += (1.0/len(tokens))\n",
        "        except KeyError:\n",
        "           Dict[i] = (1.0/len(tokens))  \n",
        "    \n",
        "    return Dict"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5pcsa66ktUR"
      },
      "source": [
        "# Training and validation of the classifier\n",
        "def trainClassifier(trainData):\n",
        "    print(\"Training Classifier...\")\n",
        "    pipeline =  Pipeline([('svc', LinearSVC())])\n",
        "    return SklearnClassifier(pipeline).train(trainData)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "herFK4Xm0Glm"
      },
      "source": [
        "Question 3\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Po2xukv7sJxy"
      },
      "source": [
        "# QUESTION 3\n",
        "#cross validation is done to predict accuracy, precision, recall, fscore\n",
        "#train a classifier to do a 10-fold cross validation on the training data\n",
        "def crossValidate(dataset, folds):\n",
        "    #data set which is sorted base on their class\n",
        "    shuffle(dataset)\n",
        "    cv_results = []\n",
        "    foldSize = int(len(dataset)/folds)\n",
        "    for i in range(0,len(dataset),foldSize):\n",
        "        classifier = trainClassifier(dataset[:i]+dataset[foldSize+i:])\n",
        "        pred = predictLabels(dataset[i:i+foldSize],classifier)\n",
        "        #formulae to predict accuracy\n",
        "        a = accuracy_score(list(map(lambda d : d[1], dataset[i:i+foldSize])), pred)\n",
        "        #formulae to predict precision, recall, fscore\n",
        "        (p,r,f,_) = precision_recall_fscore_support(list(map(lambda d : d[1], dataset[i:i+foldSize])), pred, average ='weighted')\n",
        "        #print(a,p,r,f)\n",
        "        #stores the precision, recall, f1 score, and accuracy of the classifier in a variable cv_results\n",
        "        cv_results.append((a,p,r,f))\n",
        "    cv_results = (np.mean(np.array(cv_results),axis=0))\n",
        "    return cv_results"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOxrOFZjsjaY"
      },
      "source": [
        "# Predicting labels of the classifier\n",
        "\n",
        "def predictLabels(reviewSamples, classifier):\n",
        "    return classifier.classify_many(map(lambda t: t[0], reviewSamples))\n",
        "\n",
        "def predictLabel(reviewSample, classifier):\n",
        "    return classifier.classify(toFeatureVector(preProcess(reviewSample)))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Q6lszVhktUb",
        "outputId": "b046812e-8559-496c-f122-ec2122a88a6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "# MAIN\n",
        "\n",
        "# loading reviews from the file\n",
        "# initialize global lists that will be appended to by the methods below\n",
        "rawData = []          # the filtered data from the dataset file (21000 samples)\n",
        "trainData = []        # the training data as a percentage of the total dataset (80% or 16800 samples)\n",
        "testData = []         # the test data as a percentage of the total dataset (20% or 4200 samples)\n",
        "\n",
        "# the o/p class\n",
        "fakeLabel = 'fake review'\n",
        "realLabel = 'real review'\n",
        "\n",
        "# references to the data files\n",
        "reviewPath = 'amazon_reviews.txt'\n",
        "\n",
        "# Do the actual stuff (i.e. call the functions we've made)\n",
        "# We parse the dataset and put it in a raw data list\n",
        "print(\"Now %d rawData, %d trainData, %d testData\" % (len(rawData), len(trainData), len(testData)),\n",
        "      \"Preparing the dataset...\",sep='\\n')\n",
        "loadData(reviewPath) \n",
        "# We split the raw dataset into a set of training data and test data (80/20)\n",
        "print(\"Now %d rawData, %d trainData, %d testData\" % (len(rawData), len(trainData), len(testData)),\n",
        "      \"Preparing training and test data...\",sep='\\n')\n",
        "splitData(0.8)\n",
        "# We print the number of training samples and the number of features in dataset after split\n",
        "print(\"Now %d rawData, %d trainData, %d testData\" % (len(rawData), len(trainData), len(testData)),\n",
        "      \"Training Samples: \", len(trainData), \"Features: \", len(featureDict), sep='\\n')\n",
        "# QUESTION 3 - Make sure there is a function call here to the\n",
        "# crossValidate function on the training set to get your results(a,p,r,f)\n",
        "#10-fold cross validation on the training data\n",
        "print(\"Mean of cross-validations (Accuracy, Precision, Recall, F1 score): \", crossValidate(trainData, 10))\n",
        "#using metadata features from data set helps to increase a,p,r,f "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Now 0 rawData, 0 trainData, 0 testData\n",
            "Preparing the dataset...\n",
            "Now 21000 rawData, 0 trainData, 0 testData\n",
            "Preparing training and test data...\n",
            "Now 21000 rawData, 16800 trainData, 4200 testData\n",
            "Training Samples: \n",
            "16800\n",
            "Features: \n",
            "512235\n",
            "Training Classifier...\n",
            "Training Classifier...\n",
            "Training Classifier...\n",
            "Training Classifier...\n",
            "Training Classifier...\n",
            "Training Classifier...\n",
            "Training Classifier...\n",
            "Training Classifier...\n",
            "Training Classifier...\n",
            "Training Classifier...\n",
            "Mean of cross-validations (Accuracy, Precision, Recall, F1 score):  [0.78607143 0.78805923 0.78607143 0.78577225]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovp9MSK8ktUg"
      },
      "source": [
        "# Evaluate on test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idJygajgktUh",
        "outputId": "620219d6-f115-4c5d-9c03-d6d90ba6fa1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "# testing on the test set\n",
        "functions_complete = True  # set to True once you're happy with your methods for cross validation\n",
        "if functions_complete:\n",
        "    print(testData[0])                                # have a look at the first test data instance\n",
        "    classifier = trainClassifier(trainData) \n",
        "    testTrue = [t[1] for t in testData]               # get the ground-truth labels from the data\n",
        "    testPred = predictLabels(testData, classifier)    # classify the test data to get predicted labels\n",
        "    a = accuracy_score(testTrue, testPred)            #evaluation of accuracy in test data\n",
        "    finalScores = precision_recall_fscore_support(testTrue, testPred, average='weighted') # evaluation of p,r,f in test data\n",
        "    print(\"Done training!\")\n",
        "    print(\"accuracy: \", a)                                            #print accuracy after evaluating on test set\n",
        "    print(\"Precision: %f\\nRecall: %f\\nF1 Score:%f\" % finalScores[:3]) #print p,r,f after evaluating on test set"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "({700: 1.0, 2: 1.0, 4106: 0.14285714285714285, 31: 0.2857142857142857, 170: 0.14285714285714285, 168: 0.14285714285714285, 32: 0.14285714285714285, 117: 0.14285714285714285, 438297: 0.04, 438298: 0.04, 438299: 0.04, 438300: 0.04, 52406: 0.04, 49122: 0.04, 20715: 0.04, 200915: 0.04, 438301: 0.04, 177504: 0.04, 438302: 0.04, 438303: 0.04, 494: 0.04, 15973: 0.04, 370: 0.04, 220854: 0.04, 92: 0.04, 105: 0.04, 211: 0.04, 206: 0.04, 3885: 0.04, 2923: 0.04, 1694: 0.04, 4644: 0.04, 4572: 0.04}, 'fake review')\n",
            "Training Classifier...\n",
            "Done training!\n",
            "accuracy:  0.8028571428571428\n",
            "Precision: 0.806599\n",
            "Recall: 0.802857\n",
            "F1 Score:0.802254\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}